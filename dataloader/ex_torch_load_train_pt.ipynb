{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JennEYoon/pytorch-practice/blob/main/dataloader/ex_torch_load_train_pt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is an explanation and example of using `torch.load(train.pt)` in PyTorch.\n",
        "\n",
        "The `torch.load()` function in PyTorch is used to load objects saved with `torch.save()` from a file. This function deserializes the data and loads it into memory. The `train.pt` file, in this context, is assumed to be a file containing a saved PyTorch object. This object could be a model's state dictionary, an entire model, or any other Python object that can be serialized.\n",
        "\n",
        "**Example**\n",
        "\n",
        "Assume that the `train.pt` file contains the saved state dictionary of a model. The following code snippet demonstrates how to load this state dictionary and then load the state dict into a model."
      ],
      "metadata": {
        "id": "jus58oQa2Vmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define a simple model (must match the architecture of the saved model)\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleModel, self).__init__()\n",
        "        self.linear = nn.Linear(10, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "# Create an instance of the model\n",
        "model = SimpleModel()\n",
        "\n",
        "# Load the state dictionary from the file\n",
        "try:\n",
        "    state_dict = torch.load(\"train.pt\")\n",
        "    # Load the state dictionary into the model\n",
        "    model.load_state_dict(state_dict)\n",
        "    print(\"Model state dictionary loaded successfully!\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: train.pt file not found.\")\n",
        "except RuntimeError as e:\n",
        "     print(f\"Error loading state_dict: {e}\")\n",
        "\n",
        "# Set the model to evaluation mode (important for inference)\n",
        "model.eval()\n",
        "\n",
        "# Now the model is ready to be used for inference\n",
        "# Example usage:\n",
        "input_tensor = torch.randn(1, 10)  # Example input tensor\n",
        "with torch.no_grad():\n",
        "    output = model(input_tensor)\n",
        "    print(\"Model output:\", output)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "KjCoNlRw2Vml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation**\n",
        "\n",
        "1.  **Import necessary libraries:** The code begins by importing the `torch` and `torch.nn` libraries.\n",
        "2.  **Define the model architecture:** A `SimpleModel` class is defined, representing the neural network architecture. It's crucial that this architecture matches the one used when the `train.pt` file was created.\n",
        "3.  **Create a model instance:** An instance of the `SimpleModel` is created.\n",
        "4.  **Load the state dictionary:**\n",
        "    *   The `torch.load(\"train.pt\")` function attempts to load the object stored in the `train.pt` file. It's placed in a try-except block to handle potential errors like the file not being found.\n",
        "    *   It's assumed that the loaded object is a state dictionary. If the saved object is the model itself, then the loading process will be different.\n",
        "5.  **Load the state\\_dict into the model:** The model's `load_state_dict()` method is used to load the saved parameters into the model.\n",
        "6.  **Set the model to evaluation mode:** `model.eval()` is called to set the model to evaluation mode. This is important because it disables training-specific features like dropout and batch normalization, ensuring consistent results during inference.\n",
        "7.  **Perform inference:** An example input tensor is created, and the model is used to generate an output. The `torch.no_grad()` context manager is used to disable gradient calculation during inference, which can improve performance.\n",
        "\n",
        "**Important Considerations**\n",
        "\n",
        "*   **File Path:** Ensure that the path provided to `torch.load()` is correct and that the file exists at that location.\n",
        "*   **Matching Architecture:** The model architecture defined in the code must match the architecture of the model whose state dictionary was saved in `train.pt`. Otherwise, the loading process will fail or produce unexpected results.\n",
        "*   **Device Mapping:** If the model was trained on a GPU, you might need to use the `map_location` argument in `torch.load()` to load it correctly on a CPU or a different GPU.\n",
        "*   **Security:** Be cautious when loading files from untrusted sources, as deserialization can pose security risks.\n",
        "*   **Saving the Entire Model vs. State Dictionary:** It is generally recommended to save and load the model's `state_dict` rather than saving the entire model. This provides more flexibility and avoids potential issues related to code changes.\n",
        "*   **Error Handling:** It is important to handle potential errors during the loading process, such as `FileNotFoundError` if the file does not exist or `RuntimeError` if there is an issue with the file content.\n",
        "\n",
        "This example demonstrates a common scenario of loading a model's state dictionary. The specific implementation might vary depending on the contents of the `train.pt` file and the specific use case."
      ],
      "metadata": {
        "id": "hLsKBUrJ2Vmm"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}